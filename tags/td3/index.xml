<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>td3 on Jan Kaiser | Personal Homepage</title><link>https://jank324.github.io/tags/td3/</link><description>Recent content in td3 on Jan Kaiser | Personal Homepage</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><copyright>© 2023</copyright><lastBuildDate>Tue, 06 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://jank324.github.io/tags/td3/index.xml" rel="self" type="application/rss+xml"/><item><title>Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning</title><link>https://jank324.github.io/posts/publications/kaiser2023learning/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://jank324.github.io/posts/publications/kaiser2023learning/</guid><description>J. Kaiser1, C. Xu2, A. Eichler1, A. Santamaria Garcia2, O. Stein1, E. Bründermann2, W. Kuropka1, H. Dinter1, F. Mayet1, T. Vinatier1, F. Burkart1, H. Schlarb1
1Deutsches Elektronen-Synchrotron DESY, 2 Karlsruhe Institute of Technology KIT
arXiv
Abstract # Online tuning of real-world plants is a complex optimisation problem that continues to require manual intervention by experienced human operators. Autonomous tuning is a rapidly expanding field of research, where learning-based methods, such as Reinforcement Learning-trained Optimisation (RLO) and Bayesian optimisation (BO), hold great promise for achieving outstanding plant performance and reducing tuning times.</description></item></channel></rss>