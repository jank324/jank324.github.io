[{"content":"Hello, world! ðŸ¦¦\nAttention! ðŸš§ This webpage is currently under construction. Please check back later. ðŸš§ About Me # I am a doctoral researcher with a background in Computer Science and a passion for AI, currently completing my PhD at Deutsches Elektronen-Synchrotron DESY in Hamburg, Germany. My research focuses on the development of machine learning-based algorithms towards the goal of autonomous particle accelerator operations with a strong focus on control and tuning using reinforcement learning. My other research interests include surrogate modelling and virtual diagnostics using a variety of supervised learning methods.\nDownload my CV Publications # Alfa Romeo 1300 GT 23 August 2023 Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning \u0026#8599; \u0026#8598; 6 June 2023 Beam Trajectory Control with Lattice-agnostic Reinforcement Learning \u0026#8599; \u0026#8598; 7 May 2023 EuXFEL virtual diagnostics\nZihan paper\n\u0026lt;b\u0026gt;Jan Kaiser\u0026lt;/b\u0026gt;, Oliver Stein and Annika Eichler. Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World Training. In Proceedings of the 39th International Conference on Machine Learning (ICML), 2022. Accelerating linear beam dynamics\nFirst steps\ndesigning recurrent neural networks\nDo we need real data?\nProjects # Any sufficiently advanced technology is indistinguishable from magic.\nRL4AA Collaboration \u0026#8599; \u0026#8598; 20 February 2023 desy-ml/cheetah Fast particle accelerator optics simulation for reinforcement learning and optimisation applications. Jupyter Notebook 5 3 Personal projects # I am the the master of my fate, I am the captain of my soul.\n8mm film scanner jank324/8mm-film-scanner Conversion of an old projector to a Regular 8 and Super 8 film scanner. Jupyter Notebook 3 0 Shutter speed tester?\nLocation finder?\nPhotography # Some photos \u0026hellip;?\n","date":"23 August 2023","permalink":"/","section":"","summary":"Hello, world!","title":""},{"content":" Alfa Romeo 1300 GT # Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning \u0026#8599; \u0026#8598; 6 June 2023 ","date":"23 August 2023","permalink":"/test/","section":"","summary":"Cool car ðŸš—","title":"Alfa Romeo 1300 GT"},{"content":"","date":"23 August 2023","permalink":"/tags/car/","section":"Tags","summary":"","title":"car"},{"content":"","date":"23 August 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"23 August 2023","permalink":"/tags/test/","section":"Tags","summary":"","title":"test"},{"content":"J. Kaiser1, C. Xu2, A. Eichler1, A. Santamaria Garcia2, O. Stein1, E. BrÃ¼ndermann2, W. Kuropka1, H. Dinter1, F. Mayet1, T. Vinatier1, F. Burkart1, H. Schlarb1\n1Deutsches Elektronen-Synchrotron DESY, 2 Karlsruhe Institute of Technology KIT\narXiv\nAbstract # Online tuning of real-world plants is a complex optimisation problem that continues to require manual intervention by experienced human operators. Autonomous tuning is a rapidly expanding field of research, where learning-based methods, such as Reinforcement Learning-trained Optimisation (RLO) and Bayesian optimisation (BO), hold great promise for achieving outstanding plant performance and reducing tuning times. Which algorithm to choose in different scenarios, however, remains an open question. Here we present a comparative study using a routine task in a real particle accelerator as an example, showing that RLO generally outperforms BO, but is not always the best choice. Based on the study\u0026rsquo;s results, we provide a clear set of criteria to guide the choice of algorithm for a given tuning task. These can ease the adoption of learning-based autonomous tuning solutions to the operation of complex real-world plants, ultimately improving the availability and pushing the limits of operability of these facilities, thereby enabling scientific and engineering advancements.\nRead the paper: https://arxiv.org/abs/2306.03739\nContact: Jan Kaiser Chenran Xu\n","date":"6 June 2023","permalink":"/posts/kaiser2023learning/","section":"Posts","summary":"A paper","title":"Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning"},{"content":"J. Kaiser1, C. Xu2, A. Eichler1, A. Santamaria Garcia2, O. Stein1, E. BrÃ¼ndermann2, W. Kuropka1, H. Dinter1, F. Mayet1, T. Vinatier1, F. Burkart1, H. Schlarb1\n1Deutsches Elektronen-Synchrotron DESY, 2 Karlsruhe Institute of Technology KIT\narXiv\nAbstract # Online tuning of real-world plants is a complex optimisation problem that continues to require manual intervention by experienced human operators. Autonomous tuning is a rapidly expanding field of research, where learning-based methods, such as Reinforcement Learning-trained Optimisation (RLO) and Bayesian optimisation (BO), hold great promise for achieving outstanding plant performance and reducing tuning times. Which algorithm to choose in different scenarios, however, remains an open question. Here we present a comparative study using a routine task in a real particle accelerator as an example, showing that RLO generally outperforms BO, but is not always the best choice. Based on the study\u0026rsquo;s results, we provide a clear set of criteria to guide the choice of algorithm for a given tuning task. These can ease the adoption of learning-based autonomous tuning solutions to the operation of complex real-world plants, ultimately improving the availability and pushing the limits of operability of these facilities, thereby enabling scientific and engineering advancements.\nRead the paper: https://arxiv.org/abs/2306.03739\nContact: Jan Kaiser Chenran Xu\n","date":"6 June 2023","permalink":"/publications/kaiser2023learning/","section":"Publications","summary":"A paper","title":"Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning"},{"content":"","date":"6 June 2023","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"6 June 2023","permalink":"/publications/","section":"Publications","summary":"","title":"Publications"},{"content":"","date":"7 May 2023","permalink":"/posts/xu2023latticeagnostic/","section":"Posts","summary":"A paper","title":"Beam Trajectory Control with Lattice-agnostic Reinforcement Learning"},{"content":"","date":"7 May 2023","permalink":"/publications/xu2023latticeagnostic/","section":"Publications","summary":"A paper","title":"Beam Trajectory Control with Lattice-agnostic Reinforcement Learning"},{"content":"J. Kaiser, O. Stein, A. Eichler\nDeutsches Elektronen-Synchrotron DESY\n39th International Conference on Machine Learning\nAbstract # In recent work, it has been shown that reinforcement learning (RL) is capable of solving a variety of problems at sometimes super-human performance levels. But despite continued advances in the field, applying RL to complex real-world control and optimisation problems has proven difficult. In this contribution, we demonstrate how to successfully apply RL to the optimisation of a highly complex real-world machine â€“ specifically a linear particle accelerator â€“ in an only partially observable setting and without requiring training on the real machine. Our method outperforms conventional optimisation algorithms in both the achieved result and time taken as well as already achieving close to human-level performance. We expect that such automation of machine optimisation will push the limits of operability, increase machine availability and lead to a paradigm shift in how such machines are operated, ultimately facilitating advances in a variety of fields, such as science and medicine among many others.\nRead the paper: https://proceedings.mlr.press/v162/kaiser22a.html\nContact: Jan Kaiser\n","date":"7 May 2023","permalink":"/posts/kaiser2022learningbased/","section":"Posts","summary":"A paper","title":"Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World Training"},{"content":"J. Kaiser, O. Stein, A. Eichler\nDeutsches Elektronen-Synchrotron DESY\n39th International Conference on Machine Learning\nAbstract # In recent work, it has been shown that reinforcement learning (RL) is capable of solving a variety of problems at sometimes super-human performance levels. But despite continued advances in the field, applying RL to complex real-world control and optimisation problems has proven difficult. In this contribution, we demonstrate how to successfully apply RL to the optimisation of a highly complex real-world machine â€“ specifically a linear particle accelerator â€“ in an only partially observable setting and without requiring training on the real machine. Our method outperforms conventional optimisation algorithms in both the achieved result and time taken as well as already achieving close to human-level performance. We expect that such automation of machine optimisation will push the limits of operability, increase machine availability and lead to a paradigm shift in how such machines are operated, ultimately facilitating advances in a variety of fields, such as science and medicine among many others.\nRead the paper: https://proceedings.mlr.press/v162/kaiser22a.html\nContact: Jan Kaiser\n","date":"7 May 2023","permalink":"/publications/kaiser2022learningbased/","section":"Publications","summary":"A paper","title":"Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World Training"},{"content":"","date":"20 February 2023","permalink":"/projects/","section":"Projects","summary":"","title":"Projects"},{"content":"","date":"20 February 2023","permalink":"/projects/rl4aa-collaboration/","section":"Projects","summary":"A paper","title":"RL4AA Collaboration"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]